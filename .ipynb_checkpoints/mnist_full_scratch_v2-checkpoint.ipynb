{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3941545a-d7ce-4cfc-9cc9-cac12519efdf",
   "metadata": {},
   "source": [
    "# MNIST DIGIT CLASSIFIER\n",
    "A simple 2 hidden layer learner class made for recognizing MNIST digits between 0 and 9\n",
    "\n",
    "All neural network code was created from scratch with no machine learning specific libraries\n",
    "\n",
    "PyTorch tensors were used as the data storage and data matrix representations of choice to speed up calculations and to enable training on a GPU\n",
    "\n",
    "FastAI was used to download and open the MNIST dataset\n",
    "\n",
    "PyTorch .backward() and .requires_grad_() were used to obtain the graditents needed to execute batch gradient descent.\n",
    "\n",
    "All other code was written from scratch by Sasha Kiselev with inspiration and explanation from \"Practical Deep Learning for Coders\" by Jeremy Howard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cafa31-fea0-4a9a-a0ec-9e1e1f82981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d83885-2214-48f2-8de8-66204ce28aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')],\n",
       " (#10) [Path('testing/0'),Path('testing/1'),Path('testing/2'),Path('testing/3'),Path('testing/4'),Path('testing/5'),Path('testing/6'),Path('testing/7'),Path('testing/8'),Path('testing/9')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = (path/'training').ls().sorted()\n",
    "valid_paths = (path/'testing').ls().sorted()\n",
    "train_paths, valid_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e18509-f746-4aab-9592-951e0870ca73",
   "metadata": {},
   "source": [
    "#### Dataloader creation - should be changed to have all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f26146-8397-4dd2-9f50-e7e4d6692b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_lst = [tensor(Image.open(file)) for cat in train_paths for file in cat.ls()]\n",
    "train_x_tns = torch.stack(train_x_lst)\n",
    "# change rank 3 tns to rank 2 tns so that each example is 1 row\n",
    "train_x_tns = train_x_tns.view(-1, 28*28)\n",
    "# normalize all greyscale values\n",
    "train_x_tns = train_x_tns.float()/255  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe76424c-e302-4564-a74a-f699c4d8d4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(train_x_tns[55000].view(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6938de8a-0b5e-4936-9696-cabb7bbaceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_lst = [tensor(Image.open(file)) for cat in valid_paths for file in cat.ls()]\n",
    "valid_x_tns = torch.stack(valid_x_lst)\n",
    "# change rank 3 tns to rank 2 tns so that each example is 1 row\n",
    "valid_x_tns = valid_x_tns.view(-1, 28*28)\n",
    "# normalize all greyscale values\n",
    "valid_x_tns = valid_x_tns.float()/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "304f9062-d48e-4c0e-a362-44896a45a3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(valid_x_tns[6000].view(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8242f27e-b2bf-4928-b5f6-893b690672e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = [len(cat_path.ls()) for cat_path in train_paths]\n",
    "valid_counts = [len(cat_path.ls()) for cat_path in valid_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb33878-1c76-42cf-8471-b48a366b0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tensors of labels. As x is in order, labels also in order and depend only on the count \n",
    "# of examples in the folder, unsqueeze is needed to make it same rank as x\n",
    "train_y_tns = L([])\n",
    "for i, count in enumerate(train_counts):\n",
    "    train_y_tns += L([i] * count)\n",
    "train_y_tns = tensor(train_y_tns).unsqueeze(1)\n",
    "\n",
    "valid_y_tns = L([])\n",
    "for i, count in enumerate(valid_counts):\n",
    "    valid_y_tns += L([i] * count)\n",
    "valid_y_tns = tensor(valid_y_tns).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a7290c-3efb-4913-aa1b-190ddf69f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = list(zip(train_x_tns, train_y_tns))\n",
    "valid_dset = list(zip(valid_x_tns, valid_y_tns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f6a5ada-dbe7-4c43-8f51-f00fd225f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dset, bs=256, shuffle=True)\n",
    "valid_dl = DataLoader(valid_dset, bs=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c006f8-33de-4421-a7a3-07334acafaf8",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3a1a08b-f36f-4188-a04d-753a82cf9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = torch.exp(x)\n",
    "    sum_exp = x.sum(dim = 1, keepdims = True)\n",
    "    return x / sum_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "71ca97ee-124a-46e0-bf8f-57775e388362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoHLLearner:\n",
    "    \n",
    "    def __init__(self, dls, n_hs, n_cat, lr=0.3): \n",
    "        # dls - tuple of train dataloader and valid dataloader respectivly\n",
    "        # n_hs tuple neurons in hidden layer 1 and 2 respectivly\n",
    "        n_h1, n_h2 = n_hs\n",
    "        self.train_dl, self.valid_dl = dls\n",
    "        self.lr = lr\n",
    "        \n",
    "        \n",
    "        \n",
    "        # initialize all parameters of the model and save them for tuple for easy passing\n",
    "        self.w1, self.b1 = self.init_param((28*28, n_h1)), self.init_param((1, n_h1))\n",
    "        self.w2, self.b2 = self.init_param((n_h1, n_h2)), self.init_param((1, n_h2))\n",
    "        self.w3, self.b3 = self.init_param((n_h2, n_cat)), self.init_param((1))\n",
    "        self.params = self.w1, self.b1, self.w2, self.b2, self.w3, self.b3\n",
    "    \n",
    "    def init_param(self, shape, scale = 0.01): \n",
    "        return (torch.randn(shape) * scale).requires_grad_()\n",
    "    \n",
    "    def fit(self, num_epochs):\n",
    "        for i in range(num_epochs):\n",
    "            self.train_epoch()\n",
    "            \n",
    "    def train_epoch(self):\n",
    "        #print(self.w1.mean())\n",
    "        for xb, yb in self.train_dl:\n",
    "            # make prediction and get gradient of all parameters\n",
    "            pred = self.model(xb)\n",
    "            loss = self.loss_multi(pred, yb)\n",
    "            #print(yb.shape)\n",
    "            #yb = yb.view(yb.shape[0],)\n",
    "            #print(yb.shape)\n",
    "            #print(pred, yb)\n",
    "            \n",
    "            #loss = nn.CrossEntropyLoss(pred, yb)\n",
    "            loss.backward()\n",
    "            # update parameters and make sure to reset grad back to zero \n",
    "            # as grad adds up\n",
    "            for p in self.params:\n",
    "                p.data -= self.lr * p.grad\n",
    "                p.grad.zero_()\n",
    "        print(self.valid_acc(), end='% ')\n",
    "        #print(self.valid_loss())\n",
    "        \n",
    "    def model(self, xb): \n",
    "        # basic linear relu linear relu model\n",
    "        res = (xb @ self.w1 + self.b1).max(tensor(0.))\n",
    "        res = (res @ self.w2 + self.b2).max(tensor(0.))\n",
    "        res = res @ self.w3 + self.b3\n",
    "        return res\n",
    "    \n",
    "    def loss_binary(self, pred, target): \n",
    "        pred = pred.sigmoid()\n",
    "        return torch.where(target == 1, 1 - pred, pred).mean()\n",
    "    \n",
    "    def loss_multi(self, pred, target):\n",
    "        pred = softmax(pred)\n",
    "        targets = torch.zeros(pred.shape)\n",
    "        indicies = torch.arange(pred.shape[0]), target.view(target.shape[0])\n",
    "        values = torch.ones(pred.shape[0])\n",
    "        targets.index_put_(indicies, values)\n",
    "        #print(targets, pred, abs(targets - pred))\n",
    "        return abs(targets - pred).mean()\n",
    "                                \n",
    "    \n",
    "    def valid_loss(self):\n",
    "        loss = 0.\n",
    "        for xb, yb in self.valid_dl:\n",
    "            pred = self.model(xb)\n",
    "            loss += self.loss_multi(pred, yb)\n",
    "        return loss\n",
    "    \n",
    "    def valid_acc(self):\n",
    "        batch_accs = []\n",
    "        #print(first(self.valid_dl)[0][0])\n",
    "        \n",
    "        \n",
    "        for xb, yb in self.valid_dl:\n",
    "            pred = self.model(xb)\n",
    "            pred = pred.max(dim=1)[1]\n",
    "            corrects = torch.where(pred == yb.view(yb.shape[0]), 1., 0.)\n",
    "#            print(corrects.mean())\n",
    "            #pred = torch.where(sigmoid(self.model(xb)) > 0.5, 1., 0.)\n",
    "            batch_accs.append(corrects.mean())\n",
    "        return tensor(batch_accs).mean().item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "071818c8-4a62-4afc-b547-a47306b30613",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = TwoHLLearner((train_dl, valid_dl), (32, 16), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6be53729-0026-45e7-baad-248981e1895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.8984375% 21.201172471046448% 27.031248807907104% 29.345703125% 29.599609971046448% 29.248046875% 29.296875% 29.736328125% 29.970702528953552% 30.214843153953552% 30.126953125% 31.083983182907104% 31.308594346046448% 31.943359971046448% 32.31445252895355% 33.037108182907104% 34.326171875% 37.353515625% 38.037109375% 38.603514432907104% 43.64257752895355% 48.98437559604645% 51.85546875% 53.144532442092896% 52.851563692092896% 53.33007574081421% 53.94531488418579% 54.35546636581421% 54.25781011581421% 9.5703125% 9.716796875% 10.15625% 9.86328125% 9.716796875% 9.716796875% 9.86328125% 9.716796875% 9.86328125% 9.86328125% 9.86328125% "
     ]
    }
   ],
   "source": [
    "learner.fit(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4e87e89f-cc73-433f-b87d-4a412fab91e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 10]), tensor([1.0000, 1.0000], grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = softmax(learner.model(first(train_dl)[0])[0:2])\n",
    "test.shape, test.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd5a5900-fbc0-4b24-8fe3-36579614cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.zeros(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39e2e3fb-6bf2-4c19-9f4d-3fbf6b141ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67694eb7-674a-44bb-a1e7-9ca71a751797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies = torch.arange(targets.shape[0]), tensor([1,2,2])\n",
    "values = torch.ones(targets.shape[0])\n",
    "targets.index_put_(indicies, values)\n",
    "targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8e6e1c7-65cd-4daf-8a9a-59bd128dca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 0.],\n",
       "        [0., 1., 1., 0.],\n",
       "        [0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64334233-a0d9-4042-9f9b-91fcee5ea21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_multi(pred, target):\n",
    "        pred = softmax(pred)\n",
    "        targets = torch.zeros(pred.shape)\n",
    "        indicies = torch.arange(pred.shape[0]), target.view(target.shape[0])\n",
    "        values = torch.ones(pred.shape[0])\n",
    "        targets.index_put_(indicies, values)\n",
    "        #print(targets, pred, abs(targets - pred))\n",
    "        return abs(targets - pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63d56790-4da8-4cb5-bb7a-93581423c255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3939)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_multi(tensor([2., 5., 1.], [4.,2.,6.]), tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8fee6ad-9641-4b69-adfd-18a6cabff37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7813)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_multi(tensor([2., 8., 3.], [4.,9.,7.]), tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58b0a124-e9d1-4457-a12e-a2a90eced1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 10.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1., 12.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1., 15.,  1.],\n",
       "        [ 1., 18.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, 6, dtype=torch.float)\n",
    "indices = (torch.LongTensor([0, 1, 2, 3]), torch.LongTensor([1, 3, 4, 1]))\n",
    "value = torch.tensor([10, 12, 15, 18], dtype=torch.float)\n",
    "x.index_put_(indices, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ba45444c-b9a5-4875-a38c-fcfd3db7213f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "714147a5-acb5-45f3-b82c-baf290c7bea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7708, -1.0873,  1.3952, -2.1117,  0.1558],\n",
       "         [ 0.1431, -0.2196, -0.4500,  1.2518, -0.5842],\n",
       "         [ 1.2101,  0.7075, -0.7269,  1.1045, -0.1766]], requires_grad=True),\n",
       " tensor([3, 4, 1]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186df6c-dfc3-4942-8a90-0b809b79a5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
