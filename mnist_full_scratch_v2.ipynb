{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3941545a-d7ce-4cfc-9cc9-cac12519efdf",
   "metadata": {},
   "source": [
    "# MNIST DIGIT CLASSIFIER\n",
    "A simple 2 hidden layer learner class made for recognizing MNIST digits between 0 and 9\n",
    "\n",
    "All neural network code was created from scratch with no machine learning specific libraries\n",
    "\n",
    "PyTorch tensors were used as the data storage and data matrix representations of choice to speed up calculations and to enable training on a GPU\n",
    "\n",
    "FastAI was used to download and open the MNIST dataset\n",
    "\n",
    "PyTorch .backward() and .requires_grad_() were used to obtain the graditents needed to execute batch gradient descent.\n",
    "\n",
    "All other code was written from scratch by Sasha Kiselev with inspiration and explanation from \"Practical Deep Learning for Coders\" by Jeremy Howard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cafa31-fea0-4a9a-a0ec-9e1e1f82981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d83885-2214-48f2-8de8-66204ce28aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')],\n",
       " (#10) [Path('testing/0'),Path('testing/1'),Path('testing/2'),Path('testing/3'),Path('testing/4'),Path('testing/5'),Path('testing/6'),Path('testing/7'),Path('testing/8'),Path('testing/9')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = (path/'training').ls().sorted()\n",
    "valid_paths = (path/'testing').ls().sorted()\n",
    "train_paths, valid_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e18509-f746-4aab-9592-951e0870ca73",
   "metadata": {},
   "source": [
    "#### Dataloader creation - should be changed to have all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f26146-8397-4dd2-9f50-e7e4d6692b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_lst = [tensor(Image.open(file)) for cat in train_paths for file in cat.ls()]\n",
    "train_x_tns = torch.stack(train_x_lst)\n",
    "# change rank 3 tns to rank 2 tns so that each example is 1 row\n",
    "train_x_tns = train_x_tns.view(-1, 28*28)\n",
    "# normalize all greyscale values\n",
    "train_x_tns = train_x_tns.float()/255  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe76424c-e302-4564-a74a-f699c4d8d4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(train_x_tns[55000].view(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6938de8a-0b5e-4936-9696-cabb7bbaceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_lst = [tensor(Image.open(file)) for cat in valid_paths for file in cat.ls()]\n",
    "valid_x_tns = torch.stack(valid_x_lst)\n",
    "# change rank 3 tns to rank 2 tns so that each example is 1 row\n",
    "valid_x_tns = valid_x_tns.view(-1, 28*28)\n",
    "# normalize all greyscale values\n",
    "valid_x_tns = valid_x_tns.float()/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "304f9062-d48e-4c0e-a362-44896a45a3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(valid_x_tns[6000].view(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8242f27e-b2bf-4928-b5f6-893b690672e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = [len(cat_path.ls()) for cat_path in train_paths]\n",
    "valid_counts = [len(cat_path.ls()) for cat_path in valid_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb33878-1c76-42cf-8471-b48a366b0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tensors of labels. As x is in order, labels also in order and depend only on the count \n",
    "# of examples in the folder, unsqueeze is needed to make it same rank as x\n",
    "train_y_tns = L([])\n",
    "for i, count in enumerate(train_counts):\n",
    "    train_y_tns += L([i] * count)\n",
    "train_y_tns = tensor(train_y_tns).unsqueeze(1)\n",
    "\n",
    "valid_y_tns = L([])\n",
    "for i, count in enumerate(valid_counts):\n",
    "    valid_y_tns += L([i] * count)\n",
    "valid_y_tns = tensor(valid_y_tns).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a7290c-3efb-4913-aa1b-190ddf69f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = list(zip(train_x_tns, train_y_tns))\n",
    "valid_dset = list(zip(valid_x_tns, valid_y_tns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6a5ada-dbe7-4c43-8f51-f00fd225f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dset, bs=256, shuffle=True)\n",
    "valid_dl = DataLoader(valid_dset, bs=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c006f8-33de-4421-a7a3-07334acafaf8",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a1a08b-f36f-4188-a04d-753a82cf9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = torch.exp(x)\n",
    "    sum_exp = x.sum(dim = 1, keepdims = True)\n",
    "    return x / sum_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56157c2f-8925-4eec-9d71-08e23366cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (torch.exp(2*x) - 1) / (torch.exp(2*x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71ca97ee-124a-46e0-bf8f-57775e388362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoHLLearner:\n",
    "    \n",
    "    def __init__(self, dls, n_hs, n_cat, lr=0.65): \n",
    "        # dls - tuple of train dataloader and valid dataloader respectivly\n",
    "        # n_hs tuple neurons in hidden layer 1 and 2 respectivly\n",
    "        n_h1, n_h2 = n_hs\n",
    "        self.train_dl, self.valid_dl = dls\n",
    "        self.lr = lr\n",
    "        \n",
    "        \n",
    "        \n",
    "        # initialize all parameters of the model and save them for tuple for easy passing\n",
    "        self.w1, self.b1 = self.init_param((28*28, n_h1)), self.init_param((1, n_h1))\n",
    "        self.w2, self.b2 = self.init_param((n_h1, n_h2)), self.init_param((1, n_h2))\n",
    "        self.w3, self.b3 = self.init_param((n_h2, n_cat)), self.init_param((1))\n",
    "        self.params = self.w1, self.b1, self.w2, self.b2, self.w3, self.b3\n",
    "    \n",
    "    def init_param(self, shape, scale=0.1): \n",
    "        return (torch.randn(shape) * scale).requires_grad_()\n",
    "    \n",
    "    def fit(self, num_epochs):\n",
    "        for i in range(num_epochs):\n",
    "            self.train_epoch()\n",
    "            \n",
    "    def train_epoch(self):\n",
    "        for xb, yb in self.train_dl:\n",
    "            # make prediction and get gradient of all parameters\n",
    "            pred = self.model(xb)\n",
    "            loss = self.loss_cross_ent(pred, yb)\n",
    "            loss.backward()\n",
    "            # update parameters and make sure to reset grad back to zero \n",
    "            # as grad adds up\n",
    "            for p in self.params:\n",
    "                p.data -= self.lr * p.grad\n",
    "                if torch.isnan(p.max()):  # check and stop network if gradient explodes\n",
    "                    print(loss, pred, xb)\n",
    "                    print(p, p.grad)\n",
    "                    raise ValueError(\"NaN found, breaking\")\n",
    "                p.grad.zero_()\n",
    "        print(self.valid_acc(), end = \"% \")\n",
    "        #print(self.w1.max().item(), self.w2.max().item(), self.w3.max().item())\n",
    "        \n",
    "    def model(self, xb): \n",
    "        # basic linear relu linear relu model\n",
    "        res = (xb @ self.w1 + self.b1).max(tensor(0.))\n",
    "        res = (res @ self.w2 + self.b2).max(tensor(0.))\n",
    "        res = tanh(res @ self.w3 + self.b3) # added to prevent exploding gradients\n",
    "        return res\n",
    "    \n",
    "    def loss_binary(self, pred, target): \n",
    "        pred = pred.sigmoid()\n",
    "        return torch.where(target == 1, 1 - pred, pred).mean()\n",
    "    \n",
    "    def loss_cross_ent(self, pred, target, epsilon=1e-8):\n",
    "        pred = softmax(pred)\n",
    "        targets = torch.zeros(pred.shape)\n",
    "        indicies = torch.arange(pred.shape[0]), target.view(target.shape[0])\n",
    "        values = torch.ones(pred.shape[0])\n",
    "        targets.index_put_(indicies, values)\n",
    "        return abs(targets - pred + epsilon).mean() # epsilon added to prevent everything being 0\n",
    "                                \n",
    "    def loss_mse(self, pred, target):\n",
    "        pass\n",
    "    def valid_loss(self):\n",
    "        loss = 0.\n",
    "        for xb, yb in self.valid_dl:\n",
    "            pred = self.model(xb)\n",
    "            loss += self.loss_multi(pred, yb)\n",
    "        return loss\n",
    "    \n",
    "    def valid_acc(self):\n",
    "        batch_accs = []\n",
    "        for xb, yb in self.valid_dl:\n",
    "            pred = self.model(xb)\n",
    "            pred = pred.max(dim=1)[1]\n",
    "            corrects = torch.where(pred == yb.view(yb.shape[0]), 1., 0.)\n",
    "            batch_accs.append(corrects.mean())\n",
    "        return round((tensor(batch_accs).mean().item() * 100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "071818c8-4a62-4afc-b547-a47306b30613",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = TwoHLLearner((train_dl, valid_dl), (32, 16), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6be53729-0026-45e7-baad-248981e1895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.1% 49.6% 61.97% 74.0% 79.54% 83.63% 85.61% 87.02% 88.13% 88.6% 89.04% 89.68% 89.57% 90.09% 90.59% 90.79% 91.14% 91.2% 91.53% 91.62% 91.92% 91.62% 91.89% 91.6% 91.92% 92.35% 92.47% 92.33% 92.51% 92.73% 92.67% 92.34% 92.84% 92.92% 92.87% 93.1% 93.11% 93.22% 93.23% 93.17% 93.29% 93.13% 93.26% 93.52% 93.58% 93.14% 93.35% 93.59% 93.47% 93.43% 93.78% 93.61% 93.62% 93.97% 93.9% 93.74% 93.95% 94.07% 94.16% 94.16% 93.96% 93.94% 93.99% 94.2% 94.27% 94.2% 94.36% 94.42% 94.1% 94.26% 94.44% 94.07% 94.54% 94.06% 94.57% 94.2% 94.39% 94.58% 94.6% 94.48% 94.39% 94.51% 94.52% 93.96% 94.43% 94.78% 94.58% 94.82% 94.66% 94.84% 94.89% 94.79% 94.77% 94.85% 94.76% 94.73% 94.93% 94.74% 94.94% 94.83% 94.66% 94.86% 95.08% 95.0% 94.62% 95.05% 94.94% 95.05% 95.05% 94.96% 95.04% 94.79% 95.11% 95.1% 94.86% 95.18% 95.13% 94.98% 95.16% 95.13% 95.0% 95.14% 95.17% 95.02% 95.18% 95.19% 94.95% 94.88% 94.79% 95.09% 95.2% 95.12% 95.06% 95.0% 95.01% 95.26% 95.3% 95.05% 95.27% 95.18% 95.08% 95.26% 95.07% 95.35% 95.35% 95.21% 95.35% 95.05% 95.29% 95.24% 95.37% 95.31% 95.42% 95.37% 95.25% 95.03% 95.46% 95.33% 95.34% 95.4% 95.34% 95.54% 95.56% 95.41% 95.45% 95.56% 95.58% 95.58% 95.62% 95.58% 95.63% 95.62% 95.63% 95.49% 95.49% 95.37% 95.68% 95.38% 95.68% 95.51% 95.38% 95.56% 95.64% 95.61% 95.56% 95.68% 95.39% 95.68% 95.56% 95.42% 95.76% 95.71% 95.57% 95.75% 95.29% 95.74% 95.52% 95.78% 95.68% 95.79% 95.74% 95.63% 95.76% 95.76% 95.75% 95.7% 95.71% 95.48% 95.7% 95.56% 95.64% 95.76% 95.7% 95.73% 95.63% 95.83% 95.81% 95.84% 95.64% 95.73% 95.83% 95.74% 95.38% 95.56% 95.79% 95.35% 95.7% 95.78% 95.79% 95.84% 95.5% 95.66% 95.58% 95.86% 95.84% 95.86% 95.66% 95.85% 95.56% 95.67% 95.7% 95.89% 95.83% 95.85% 95.85% 95.69% 95.82% 95.39% 95.66% 95.66% 95.9% 95.83% 95.69% 95.7% 95.86% 95.92% "
     ]
    }
   ],
   "source": [
    "learner.fit(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c447d9-2966-4d69-b913-1b80159f4a82",
   "metadata": {},
   "source": [
    "Sometimes the model gets stuck around 80% accuracy on validation data, but most of the time with this training it is about to get to 95%-96% accuracy. After a succesful training run getting 95.95% I saved the model parameters to a text file for import into the inferer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3906fe56-afe4-46ae-bd42-1b7aec6a89c0",
   "metadata": {},
   "source": [
    "#### Save model parameters to a file to be used for the inferer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd5a5900-fbc0-4b24-8fe3-36579614cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learner.params, \"95.92%_acc_parameters.pt\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
