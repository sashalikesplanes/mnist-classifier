{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cafa31-fea0-4a9a-a0ec-9e1e1f82981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e18509-f746-4aab-9592-951e0870ca73",
   "metadata": {},
   "source": [
    "#### Dataloader creation - should be changed to have all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c8f26146-8397-4dd2-9f50-e7e4d6692b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_lst = [tensor(Image.open(file)) for cat in (path/'train').ls() for file in cat.ls()]\n",
    "train_x_tns = torch.stack(train_x_lst)\n",
    "# change rank 3 tns to rank 2 tns so that each example is 1 row\n",
    "train_x_tns = train_x_tns.view(-1, 28*28)\n",
    "# normalize all greyscale values\n",
    "train_x_tns = train_x_tns.float()/255  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6938de8a-0b5e-4936-9696-cabb7bbaceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_lst = [tensor(Image.open(file)) for cat in (path/'valid').ls() for file in cat.ls()]\n",
    "valid_x_tns = torch.stack(valid_x_lst)\n",
    "# change rank 3 tns to rank 2 tns so that each example is 1 row\n",
    "valid_x_tns = valid_x_tns.view(-1, 28*28)\n",
    "# normalize all greyscale values\n",
    "valid_x_tns = valid_x_tns.float()/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8242f27e-b2bf-4928-b5f6-893b690672e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3s_count = len((path/'train'/'3').ls())\n",
    "train_7s_count = len((path/'train'/'7').ls())\n",
    "valid_3s_count = len((path/'valid'/'3').ls())\n",
    "valid_7s_count = len((path/'valid'/'7').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ecb33878-1c76-42cf-8471-b48a366b0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tensors of labels. As x is in order, labels also in order and depend only on the count \n",
    "# of examples in the folder, unsqueeze is needed to make it same rank as x\n",
    "train_y_tns = tensor([1] * train_3s_count + [0] * train_7s_count).unsqueeze(1)\n",
    "valid_y_tns = tensor([1] * valid_3s_count + [0] * valid_7s_count).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5c68f622-1628-4dfe-8d43-6d4f6591c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = list(zip(train_x_tns, train_y_tns)) \n",
    "valid_dset = list(zip(valid_x_tns, valid_y_tns)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8f6a5ada-dbe7-4c43-8f51-f00fd225f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dset, bs=256, shuffle=True)\n",
    "valid_dl = DataLoader(valid_dset, bs=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c006f8-33de-4421-a7a3-07334acafaf8",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "71ca97ee-124a-46e0-bf8f-57775e388362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoHLLearner:\n",
    "    \n",
    "    def __init__(self, dls, n_hs, lr=1): \n",
    "        # dls - tuple of train dataloader and valid dataloader respectivly\n",
    "        # n_hs tuple neurons in hidden layer 1 and 2 respectivly\n",
    "        n_h1, n_h2 = n_hs\n",
    "        self.train_dl, self.valid_dl = dls\n",
    "        self.lr = lr\n",
    "        \n",
    "        # initialize all parameters of the model and save them for tuple for easy passing\n",
    "        self.w1, self.b1 = self.init_param((28*28, n_h1)), self.init_param((1, n_h1))\n",
    "        self.w2, self.b2 = self.init_param((n_h1, n_h2)), self.init_param((1, n_h2))\n",
    "        self.w3, self.b3 = self.init_param((n_h2, 1)), self.init_param((1))\n",
    "        self.params = self.w1, self.b1, self.w2, self.b2, self.w3, self.b3\n",
    "    \n",
    "    def init_param(self, shape, scale = 1): \n",
    "        return (torch.randn(shape) * scale).requires_grad_()\n",
    "    \n",
    "    def fit(self, num_epochs):\n",
    "        for i in range(num_epochs):\n",
    "            self.train_epoch()\n",
    "            \n",
    "    def train_epoch(self):\n",
    "        for xb, yb in self.train_dl:\n",
    "            # make prediction and get gradient of all parameters\n",
    "            pred = self.model(xb)\n",
    "            loss = self.loss_f(pred, yb)\n",
    "            loss.backward()\n",
    "            # update parameters and make sure to reset grad back to zero \n",
    "            # as grad adds up\n",
    "            for p in self.params:\n",
    "                p.data -= self.lr * p.grad\n",
    "                p.grad.zero_()\n",
    "        print(self.valid_acc(), end='% ')\n",
    "    \n",
    "    def model(self, xb): \n",
    "        # basic linear relu linear relu model\n",
    "        res = (xb @ self.w1 + self.b1).max(tensor(0.))\n",
    "        res = (res @ self.w2 + self.b2).max(tensor(0.))\n",
    "        res = res @ self.w3 + self.b3\n",
    "        return res\n",
    "    \n",
    "    def loss_f(self, pred, target): \n",
    "        pred = pred.sigmoid()\n",
    "        return torch.where(target == 1, 1 - pred, pred).mean()\n",
    "    \n",
    "    def valid_acc(self):\n",
    "        batch_accs = []\n",
    "        for xb, yb in self.valid_dl:\n",
    "            pred = torch.where(sigmoid(self.model(xb)) > 0.5, 1., 0.)\n",
    "            batch_accs.append(torch.where(pred == yb, 1., 0.).mean())\n",
    "        return round(tensor(batch_accs).mean().item()*100, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "071818c8-4a62-4afc-b547-a47306b30613",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = TwoHLLearner((train_dl, valid_dl), (32, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4e87e89f-cc73-433f-b87d-4a412fab91e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.94% 94.4% 94.86% 95.49% 95.73% 95.78% 95.97% 96.18% 96.18% 96.16% "
     ]
    }
   ],
   "source": [
    "learner.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd124669-0adc-409a-a878-1ce7d152f8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
